"""
è”ç½‘æœç´¢å·¥å…· - å®æ—¶è·å–æœ€æ–°ä¿¡æ¯
"""

import requests
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
import json
import re


class WebSearchTool:
    """è”ç½‘æœç´¢å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœç´¢å·¥å…·"""
        self.api_url = "https://v1.search-api.ovh/api/search"
        self.api_key = "5b926162c800936f37c77a7208e6cc619bd4c07dfa3c1401b84b6059c9eba596"
        self.headers = {
            'API-KEY': self.api_key,
            'User-Agent': 'FamilyBot/1.0'
        }
        
    def should_search(self, query: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè”ç½‘æœç´¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            æ˜¯å¦éœ€è¦æœç´¢
        """
        # å®æ—¶ä¿¡æ¯å…³é”®è¯
        real_time_keywords = [
            'ä»Šå¤©', 'ç°åœ¨', 'æœ€æ–°', 'å½“å‰', 'å®æ—¶', 'æœ€è¿‘',
            'æ–°é—»', 'è‚¡ä»·', 'æ±‡ç‡', 'å¤©æ°”', 'ç–«æƒ…', 'æ”¿ç­–',
            'å‘å¸ƒ', 'æ›´æ–°', 'å®£å¸ƒ', 'å…¬å¸ƒ', 'æŠ¥é“', 'æ¶ˆæ¯',
            'ä»Šå¹´', '2024', '2025', 'æœ¬æœˆ', 'è¿™å‘¨', 'æ˜¨å¤©',
            'ä»·æ ¼', 'å¸‚åœº', 'è‚¡å¸‚', 'æ¯”ç‰¹å¸', 'æˆ¿ä»·', 'æ²¹ä»·'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å®æ—¶ä¿¡æ¯å…³é”®è¯
        query_lower = query.lower()
        for keyword in real_time_keywords:
            if keyword in query:
                return True
                
        # æ£€æŸ¥é—®å¥æ¨¡å¼
        question_patterns = [
            r'.*æœ€æ–°.*æ€ä¹ˆæ ·',
            r'.*ç°åœ¨.*ä»·æ ¼',
            r'.*ä»Šå¤©.*å‘ç”Ÿ',
            r'.*æœ€è¿‘.*æ¶ˆæ¯',
            r'.*å½“å‰.*çŠ¶å†µ'
        ]
        
        for pattern in question_patterns:
            if re.search(pattern, query):
                return True
        
        return False
    
    async def search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            print(f"ğŸ” å¼€å§‹è”ç½‘æœç´¢: {query}")
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                'q': query,
                'num': max_results,
                'hl': 'zh-CN',
                'gl': 'CN'
            }
            
            # å‘é€å¼‚æ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: requests.get(
                    self.api_url, 
                    headers=self.headers, 
                    params=params,
                    timeout=10
                )
            )
            
            if response.status_code == 200:
                data = response.json()
                processed_results = self._process_search_results(data, query)
                print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(processed_results.get('results', []))} ä¸ªç»“æœ")
                return processed_results
            else:
                print(f"âŒ æœç´¢APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return self._create_error_result(f"æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ (é”™è¯¯ç : {response.status_code})")
                
        except asyncio.TimeoutError:
            print("âŒ æœç´¢è¯·æ±‚è¶…æ—¶")
            return self._create_error_result("æœç´¢è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except requests.RequestException as e:
            print(f"âŒ æœç´¢è¯·æ±‚å¼‚å¸¸: {e}")
            return self._create_error_result(f"ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}")
        except Exception as e:
            print(f"âŒ æœç´¢å¤„ç†å¼‚å¸¸: {e}")
            return self._create_error_result(f"æœç´¢å¤„ç†å¤±è´¥: {str(e)}")
    
    def _process_search_results(self, data: Dict, query: str) -> Dict[str, Any]:
        """
        å¤„ç†æœç´¢ç»“æœ
        
        Args:
            data: åŸå§‹æœç´¢æ•°æ®
            query: æœç´¢æŸ¥è¯¢
            
        Returns:
            å¤„ç†åçš„ç»“æœ
        """
        results = []
        
        # æå–æœç´¢ç»“æœ - æ”¯æŒå¤šç§APIå“åº”æ ¼å¼
        organic_results = []
        
        # æ£€æŸ¥SerpAPIæ ¼å¼: data.data.organic_results
        if 'data' in data and isinstance(data['data'], dict) and 'organic_results' in data['data']:
            organic_results = data['data']['organic_results']
            print(f"ğŸ” ä½¿ç”¨SerpAPIæ ¼å¼ï¼Œæ‰¾åˆ° {len(organic_results)} ä¸ªæœ‰æœºç»“æœ")
        # æ£€æŸ¥ç›´æ¥æ ¼å¼: data.results  
        elif 'results' in data and isinstance(data['results'], list):
            organic_results = data['results']
            print(f"ğŸ” ä½¿ç”¨ç›´æ¥æ ¼å¼ï¼Œæ‰¾åˆ° {len(organic_results)} ä¸ªç»“æœ")
        # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„æ ¼å¼
        elif 'organic_results' in data:
            organic_results = data['organic_results']
            print(f"ğŸ” ä½¿ç”¨æœ‰æœºç»“æœæ ¼å¼ï¼Œæ‰¾åˆ° {len(organic_results)} ä¸ªç»“æœ")
        
        # å¤„ç†æœç´¢ç»“æœ
        if organic_results and isinstance(organic_results, list):
            for item in organic_results[:5]:  # é™åˆ¶å‰5ä¸ªç»“æœ
                if isinstance(item, dict):
                    result = {
                        'title': item.get('title', '').strip(),
                        'url': item.get('link', item.get('url', '')).strip(),  # SerpAPIä½¿ç”¨'link'
                        'snippet': item.get('snippet', '').strip(),
                        'source': self._extract_domain(item.get('link', item.get('url', '')))
                    }
                    
                    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
                    if result['title'] and result['snippet']:
                        results.append(result)
                        print(f"  âœ… æ·»åŠ ç»“æœ: {result['title'][:50]}...")
        
        # æ„å»ºæ€»ç»“
        summary = self._create_search_summary(results, query)
        
        # è·å–æ€»ç»“æœæ•°ï¼ˆä»ä¸åŒå¯èƒ½çš„ä½ç½®ï¼‰
        total_count = len(results)
        if 'data' in data and isinstance(data['data'], dict):
            if 'search_information' in data['data'] and 'total_results' in data['data']['search_information']:
                total_count = data['data']['search_information']['total_results']
        elif 'total_results' in data:
            total_count = data['total_results']
        
        return {
            'query': query,
            'timestamp': datetime.now().isoformat(),
            'total_results': total_count,
            'results': results,
            'summary': summary,
            'status': 'success'
        }
    
    def _create_search_summary(self, results: List[Dict], query: str) -> str:
        """
        åˆ›å»ºæœç´¢ç»“æœæ€»ç»“
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            query: æœç´¢æŸ¥è¯¢
            
        Returns:
            æ€»ç»“æ–‡æœ¬
        """
        if not results:
            return f"å¾ˆæŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äºã€Œ{query}ã€çš„ç›¸å…³ä¿¡æ¯ã€‚"
        
        summary_parts = [f"ğŸ” å…³äºã€Œ{query}ã€çš„æœ€æ–°ä¿¡æ¯ï¼š\n"]
        
        for i, result in enumerate(results[:3], 1):  # ä½¿ç”¨å‰3ä¸ªç»“æœ
            source = result['source']
            title = result['title'][:50] + "..." if len(result['title']) > 50 else result['title']
            snippet = result['snippet'][:100] + "..." if len(result['snippet']) > 100 else result['snippet']
            
            summary_parts.append(f"{i}. ã€{source}ã€‘{title}")
            summary_parts.append(f"   {snippet}\n")
        
        # æ·»åŠ æœç´¢æ¥æºé“¾æ¥éƒ¨åˆ†
        if results:
            summary_parts.append("\nğŸ“ ä¿¡æ¯æ¥æºï¼š")
            for i, result in enumerate(results[:3], 1):
                url = result['url']
                source = result['source']
                title = result['title'][:25] + "..." if len(result['title']) > 25 else result['title']
                summary_parts.append(f"{i}. {source} - {title} [é“¾æ¥{i}]({url})")
        
        summary_parts.append(f"\nğŸ“Š å…±æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ä¿¡æ¯ï¼Œæ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        
        return "\n".join(summary_parts)
    
    def _extract_domain(self, url: str) -> str:
        """
        ä»URLæå–åŸŸå
        
        Args:
            url: å®Œæ•´URL
            
        Returns:
            åŸŸå
        """
        try:
            if url.startswith(('http://', 'https://')):
                domain = url.split('/')[2]
                return domain.replace('www.', '')
            return url
        except:
            return "æœªçŸ¥æ¥æº"
    
    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """
        åˆ›å»ºé”™è¯¯ç»“æœ
        
        Args:
            error_message: é”™è¯¯ä¿¡æ¯
            
        Returns:
            é”™è¯¯ç»“æœå­—å…¸
        """
        return {
            'query': '',
            'timestamp': datetime.now().isoformat(),
            'total_results': 0,
            'results': [],
            'summary': error_message,
            'status': 'error'
        }


# å…¨å±€æœç´¢å·¥å…·å®ä¾‹
web_search_tool = WebSearchTool()


async def perform_web_search(query: str) -> Dict[str, Any]:
    """
    æ‰§è¡Œè”ç½‘æœç´¢çš„ä¾¿æ·å‡½æ•°
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        
    Returns:
        æœç´¢ç»“æœ
    """
    return await web_search_tool.search(query)


def should_use_web_search(query: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨è”ç½‘æœç´¢çš„ä¾¿æ·å‡½æ•°
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        
    Returns:
        æ˜¯å¦éœ€è¦æœç´¢
    """
    return web_search_tool.should_search(query)
