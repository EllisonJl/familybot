"""
Graph RAG çŸ¥è¯†å¢å¼ºç³»ç»Ÿ
åŸºäºå›¾ç»“æ„çš„çŸ¥è¯†æ£€ç´¢å’Œå¢å¼ºç”Ÿæˆ
é›†æˆæ–‡æ¡£æœç´¢åŠŸèƒ½
"""

import json
import sqlite3
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime
import numpy as np
from openai import OpenAI

from config import Config
from models.state import GraphRAGResult
from rag.document_processor import document_processor


@dataclass
class KnowledgeNode:
    """çŸ¥è¯†èŠ‚ç‚¹"""
    id: str
    content: str
    node_type: str  # "concept", "fact", "advice", "story"
    domain: str     # "health", "family", "daily_life", "emotion"
    importance: float
    created_at: str
    metadata: Dict[str, Any]


@dataclass
class KnowledgeEdge:
    """çŸ¥è¯†è¾¹"""
    source_id: str
    target_id: str
    relation_type: str  # "relates_to", "caused_by", "helps_with", "example_of"
    weight: float
    metadata: Dict[str, Any]


class GraphRAGSystem:
    """Graph RAG çŸ¥è¯†å¢å¼ºç³»ç»Ÿ"""
    
    def __init__(self, db_path: Optional[str] = None):
        """åˆå§‹åŒ–Graph RAGç³»ç»Ÿ"""
        if db_path is None:
            db_dir = Path(__file__).parent.parent / "data"
            db_dir.mkdir(exist_ok=True)
            db_path = str(db_dir / "knowledge_graph.db")
        
        self.db_path = db_path
        self.client = OpenAI(
            api_key=Config.DASHSCOPE_API_KEY,
            base_url=Config.DASHSCOPE_BASE_URL
        )
        
        self._init_database()
        self._populate_initial_knowledge()
        
        print("âœ… Graph RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _init_database(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # çŸ¥è¯†èŠ‚ç‚¹è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS knowledge_nodes (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    node_type TEXT NOT NULL,
                    domain TEXT NOT NULL,
                    importance REAL DEFAULT 0.5,
                    created_at TEXT NOT NULL,
                    metadata TEXT DEFAULT '{}'
                )
            """)
            
            # çŸ¥è¯†è¾¹è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS knowledge_edges (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    source_id TEXT NOT NULL,
                    target_id TEXT NOT NULL,
                    relation_type TEXT NOT NULL,
                    weight REAL DEFAULT 1.0,
                    metadata TEXT DEFAULT '{}',
                    FOREIGN KEY (source_id) REFERENCES knowledge_nodes (id),
                    FOREIGN KEY (target_id) REFERENCES knowledge_nodes (id)
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_nodes_domain 
                ON knowledge_nodes(domain)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_nodes_type 
                ON knowledge_nodes(node_type)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_edges_source 
                ON knowledge_edges(source_id)
            """)
            
            conn.commit()
    
    def _populate_initial_knowledge(self):
        """å¡«å……åˆå§‹çŸ¥è¯†åº“"""
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM knowledge_nodes")
            count = cursor.fetchone()[0]
            
            if count > 0:
                return  # å·²æœ‰æ•°æ®ï¼Œè·³è¿‡
        
        print("ğŸ“š æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“...")
        
        # åˆå§‹çŸ¥è¯†èŠ‚ç‚¹
        initial_nodes = [
            # å¥åº·çŸ¥è¯†
            KnowledgeNode(
                id="health_001",
                content="è€å¹´äººåº”è¯¥æ¯å¤©è‡³å°‘æ•£æ­¥30åˆ†é’Ÿï¼Œæœ‰åŠ©äºæ”¹å–„å¿ƒè¡€ç®¡å¥åº·å’Œéª¨éª¼å¼ºåº¦",
                node_type="advice",
                domain="health",
                importance=0.9,
                created_at=datetime.now().isoformat(),
                metadata={"source": "åŒ»å­¦å»ºè®®", "audience": "è€å¹´äºº"}
            ),
            KnowledgeNode(
                id="health_002", 
                content="é«˜è¡€å‹æ‚£è€…åº”è¯¥å®šæœŸç›‘æµ‹è¡€å‹ï¼ŒæŒ‰æ—¶æœè¯ï¼Œå°‘ç›é¥®é£Ÿ",
                node_type="advice",
                domain="health",
                importance=0.95,
                created_at=datetime.now().isoformat(),
                metadata={"source": "åŒ»å­¦æŒ‡å—", "condition": "é«˜è¡€å‹"}
            ),
            KnowledgeNode(
                id="health_003",
                content="å……è¶³çš„ç¡çœ å¯¹è€å¹´äººå¾ˆé‡è¦ï¼Œå»ºè®®æ¯æ™š7-8å°æ—¶ï¼Œä¿æŒè§„å¾‹ä½œæ¯",
                node_type="advice", 
                domain="health",
                importance=0.8,
                created_at=datetime.now().isoformat(),
                metadata={"source": "å¥åº·æŒ‡å—", "topic": "ç¡çœ "}
            ),
            
            # æƒ…æ„Ÿæ”¯æŒçŸ¥è¯†
            KnowledgeNode(
                id="emotion_001",
                content="å½“è€äººæ„Ÿåˆ°å­¤ç‹¬æ—¶ï¼Œå¯ä»¥é€šè¿‡èŠå¤©ã€å›å¿†ç¾å¥½æ—¶å…‰ã€å¬éŸ³ä¹æ¥æ”¹å–„å¿ƒæƒ…",
                node_type="advice",
                domain="emotion",
                importance=0.85,
                created_at=datetime.now().isoformat(),
                metadata={"emotion": "loneliness", "strategies": ["chat", "music", "memories"]}
            ),
            KnowledgeNode(
                id="emotion_002",
                content="å®¶äººçš„é™ªä¼´å’Œå…³çˆ±æ˜¯è€äººå¿ƒç†å¥åº·çš„é‡è¦æ”¯æ’‘",
                node_type="fact",
                domain="emotion",
                importance=0.9,
                created_at=datetime.now().isoformat(),
                metadata={"importance": "family_support"}
            ),
            
            # å®¶åº­å…³ç³»çŸ¥è¯†
            KnowledgeNode(
                id="family_001",
                content="å®šæœŸä¸å®¶äººè”ç³»ï¼Œåˆ†äº«æ—¥å¸¸ç”Ÿæ´»ï¼Œæœ‰åŠ©äºç»´ç³»äº²æƒ…çº½å¸¦",
                node_type="advice",
                domain="family",
                importance=0.8,
                created_at=datetime.now().isoformat(),
                metadata={"activity": "communication"}
            ),
            KnowledgeNode(
                id="family_002",
                content="å­™è¾ˆçš„é™ªä¼´èƒ½ç»™è€äººå¸¦æ¥ç‰¹åˆ«çš„å¿«ä¹å’Œç”Ÿæ´»åŠ¨åŠ›",
                node_type="fact",
                domain="family",
                importance=0.85,
                created_at=datetime.now().isoformat(),
                metadata={"relationship": "grandparent-grandchild"}
            ),
            
            # æ—¥å¸¸ç”Ÿæ´»çŸ¥è¯†
            KnowledgeNode(
                id="daily_001",
                content="ä¿æŒè§„å¾‹çš„ä½œæ¯æ—¶é—´ï¼Œæœ‰åŠ©äºèº«ä½“å¥åº·å’Œæƒ…ç»ªç¨³å®š",
                node_type="advice",
                domain="daily_life",
                importance=0.75,
                created_at=datetime.now().isoformat(),
                metadata={"aspect": "routine"}
            ),
            KnowledgeNode(
                id="daily_002",
                content="é€‚å½“çš„ç¤¾äº¤æ´»åŠ¨ï¼Œå¦‚ä¸é‚»å±…èŠå¤©ã€å‚åŠ ç¤¾åŒºæ´»åŠ¨ï¼Œæœ‰ç›Šèº«å¿ƒå¥åº·",
                node_type="advice",
                domain="daily_life", 
                importance=0.8,
                created_at=datetime.now().isoformat(),
                metadata={"activity": "social"}
            )
        ]
        
        # åˆå§‹çŸ¥è¯†è¾¹
        initial_edges = [
            # å¥åº·ç›¸å…³è¿æ¥
            KnowledgeEdge("health_001", "health_003", "relates_to", 0.8, {"reason": "è¿åŠ¨å’Œç¡çœ éƒ½æ˜¯å¥åº·è¦ç´ "}),
            KnowledgeEdge("health_002", "health_001", "relates_to", 0.7, {"reason": "è¡€å‹æ§åˆ¶éœ€è¦è¿åŠ¨é…åˆ"}),
            
            # æƒ…æ„Ÿå’Œå®¶åº­è¿æ¥
            KnowledgeEdge("emotion_001", "family_001", "helps_with", 0.9, {"reason": "å®¶äººè”ç³»ç¼“è§£å­¤ç‹¬"}),
            KnowledgeEdge("emotion_002", "family_002", "example_of", 0.85, {"reason": "å­™è¾ˆé™ªä¼´æ˜¯å®¶äººæ”¯æ’‘çš„ä¾‹å­"}),
            
            # æ—¥å¸¸ç”Ÿæ´»è¿æ¥
            KnowledgeEdge("daily_001", "health_003", "relates_to", 0.9, {"reason": "è§„å¾‹ä½œæ¯åŒ…å«è§„å¾‹ç¡çœ "}),
            KnowledgeEdge("daily_002", "emotion_001", "helps_with", 0.8, {"reason": "ç¤¾äº¤æ´»åŠ¨ç¼“è§£å­¤ç‹¬æ„Ÿ"})
        ]
        
        # æ‰¹é‡æ’å…¥æ•°æ®
        self._batch_insert_nodes(initial_nodes)
        self._batch_insert_edges(initial_edges)
        
        print(f"âœ… å·²åˆå§‹åŒ– {len(initial_nodes)} ä¸ªçŸ¥è¯†èŠ‚ç‚¹å’Œ {len(initial_edges)} ä¸ªçŸ¥è¯†è¾¹")
    
    def _batch_insert_nodes(self, nodes: List[KnowledgeNode]):
        """æ‰¹é‡æ’å…¥çŸ¥è¯†èŠ‚ç‚¹"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            node_data = [
                (
                    node.id, node.content, node.node_type, node.domain,
                    node.importance, node.created_at, json.dumps(node.metadata)
                )
                for node in nodes
            ]
            
            cursor.executemany("""
                INSERT OR REPLACE INTO knowledge_nodes 
                (id, content, node_type, domain, importance, created_at, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, node_data)
            
            conn.commit()
    
    def _batch_insert_edges(self, edges: List[KnowledgeEdge]):
        """æ‰¹é‡æ’å…¥çŸ¥è¯†è¾¹"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            edge_data = [
                (
                    edge.source_id, edge.target_id, edge.relation_type,
                    edge.weight, json.dumps(edge.metadata)
                )
                for edge in edges
            ]
            
            cursor.executemany("""
                INSERT INTO knowledge_edges 
                (source_id, target_id, relation_type, weight, metadata)
                VALUES (?, ?, ?, ?, ?)
            """, edge_data)
            
            conn.commit()
    
    async def query_knowledge(
        self, 
        query: str, 
        character_id: Optional[str] = None,
        domain: Optional[str] = None, 
        limit: int = 5
    ) -> dict:
        """
        æŸ¥è¯¢çŸ¥è¯†å›¾è°±å’Œè§’è‰²æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            character_id: è§’è‰²IDï¼Œç”¨äºæœç´¢è§’è‰²ä¸“å±æ–‡æ¡£
            domain: çŸ¥è¯†åŸŸé™åˆ¶
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            çŸ¥è¯†æ£€ç´¢ç»“æœ
        """
        try:
            print(f"ğŸ” Graph RAG æŸ¥è¯¢: {query[:50]}...")
            if character_id:
                print(f"ğŸ­ è§’è‰²: {character_id}")
            
            # 1. æŸ¥è¯¢æ‰©å±• - ç”Ÿæˆç›¸å…³å…³é”®è¯
            expanded_query = await self._expand_query(query)
            
            # 2. æ£€ç´¢ç›¸å…³èŠ‚ç‚¹ï¼ˆåŸºç¡€çŸ¥è¯†å›¾è°±ï¼‰
            relevant_nodes = self._search_nodes(expanded_query, domain, limit)
            
            # 3. æœç´¢è§’è‰²æ–‡æ¡£ï¼ˆå¦‚æœæä¾›äº†è§’è‰²IDï¼‰
            document_results = []
            if character_id:
                document_results = await document_processor.search_in_character_documents(
                    character_id, query, limit
                )
                print(f"ğŸ“„ åœ¨è§’è‰²æ–‡æ¡£ä¸­æ‰¾åˆ° {len(document_results)} ä¸ªç›¸å…³ç‰‡æ®µ")
            
            # 4. å›¾éå† - æŸ¥æ‰¾ç›¸å…³è”çš„èŠ‚ç‚¹
            connected_nodes = self._find_connected_nodes(relevant_nodes, limit // 2)
            
            # 5. ç»“æœæ’åºå’Œè¿‡æ»¤
            final_results = self._rank_and_filter_results(
                relevant_nodes + connected_nodes, query, limit // 2
            )
            
            # 6. æ„å»ºç»“æœ
            contexts = []
            sources = []
            
            # æ·»åŠ çŸ¥è¯†å›¾è°±ç»“æœ
            for node, score in final_results:
                contexts.append({
                    "content": node.content,
                    "domain": node.domain,
                    "type": node.node_type,
                    "relevance_score": score,
                    "metadata": node.metadata,
                    "source": "knowledge_graph"
                })
                sources.append(f"{node.domain}_{node.node_type}")
            
            # æ·»åŠ æ–‡æ¡£æœç´¢ç»“æœ
            for doc_result in document_results:
                contexts.append({
                    "content": doc_result["content"],
                    "domain": "document",
                    "type": "document_chunk",
                    "relevance_score": doc_result["relevance_score"],
                    "metadata": {
                        "filename": doc_result["filename"],
                        "page_number": doc_result["page_number"],
                        "file_id": doc_result["file_id"]
                    },
                    "source": "character_document"
                })
                sources.append(f"document_{doc_result['filename']}")
            
            # æŒ‰ç›¸å…³æ€§æ’åº
            contexts.sort(key=lambda x: x["relevance_score"], reverse=True)
            contexts = contexts[:limit]  # é™åˆ¶æœ€ç»ˆç»“æœæ•°é‡
            
            result = GraphRAGResult(
                relevant_contexts=contexts,
                knowledge_sources=list(set(sources)),
                confidence=max([ctx["relevance_score"] for ctx in contexts]) if contexts else 0.0,
                query_expansion=expanded_query
            )
            
            print(f"âœ… Graph RAG æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(contexts)} ä¸ªç›¸å…³ä¸Šä¸‹æ–‡")
            print(f"   - çŸ¥è¯†å›¾è°±: {len([c for c in contexts if c['source'] == 'knowledge_graph'])} ä¸ª")
            print(f"   - è§’è‰²æ–‡æ¡£: {len([c for c in contexts if c['source'] == 'character_document'])} ä¸ª")
            
            return result
            
        except Exception as e:
            print(f"âŒ Graph RAG æŸ¥è¯¢å¤±è´¥: {e}")
            return GraphRAGResult(
                relevant_contexts=[],
                knowledge_sources=[],
                confidence=0.0,
                query_expansion=[query]
            )
    
    async def _expand_query(self, query: str) -> List[str]:
        """æŸ¥è¯¢æ‰©å±• - ç”Ÿæˆç›¸å…³å…³é”®è¯"""
        try:
            expansion_prompt = f"""
è¯·ä¸ºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆç›¸å…³çš„å…³é”®è¯å’ŒåŒä¹‰è¯ï¼Œå¸®åŠ©æ›´å¥½åœ°æ£€ç´¢çŸ¥è¯†ï¼š

æŸ¥è¯¢: {query}

è¯·ç”Ÿæˆ5-10ä¸ªç›¸å…³å…³é”®è¯ï¼ŒåŒ…æ‹¬ï¼š
1. æ ¸å¿ƒæ¦‚å¿µçš„åŒä¹‰è¯
2. ç›¸å…³çš„ä¸»é¢˜è¯
3. å¯èƒ½çš„æœç´¢å˜ä½“

åªè¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªï¼š
"""
            
            response = self.client.chat.completions.create(
                model=Config.LLM_MODEL,
                messages=[{"role": "user", "content": expansion_prompt}],
                temperature=0.5,
                max_tokens=200
            )
            
            expanded_terms = response.choices[0].message.content.strip().split('\n')
            expanded_terms = [term.strip('- ').strip() for term in expanded_terms if term.strip()]
            
            # æ·»åŠ åŸå§‹æŸ¥è¯¢
            return [query] + expanded_terms[:8]
            
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢æ‰©å±•å¤±è´¥: {e}")
            return [query]
    
    def _search_nodes(self, query_terms: List[str], domain: Optional[str], limit: int) -> List[Tuple[KnowledgeNode, float]]:
        """æœç´¢ç›¸å…³çŸ¥è¯†èŠ‚ç‚¹"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ„å»ºæœç´¢æ¡ä»¶
                search_conditions = []
                params = []
                
                # æ–‡æœ¬åŒ¹é…æ¡ä»¶
                for term in query_terms[:3]:  # åªä½¿ç”¨å‰3ä¸ªæœ€é‡è¦çš„è¯
                    search_conditions.append("content LIKE ?")
                    params.append(f"%{term}%")
                
                # åŸŸé™åˆ¶
                domain_condition = ""
                if domain:
                    domain_condition = "AND domain = ?"
                    params.append(domain)
                
                # æ„å»ºæŸ¥è¯¢
                where_clause = " OR ".join(search_conditions)
                if not where_clause:
                    where_clause = "1=1"
                
                query_sql = f"""
                    SELECT id, content, node_type, domain, importance, created_at, metadata
                    FROM knowledge_nodes 
                    WHERE ({where_clause}) {domain_condition}
                    ORDER BY importance DESC, created_at DESC
                    LIMIT ?
                """
                params.append(limit)
                
                cursor.execute(query_sql, params)
                rows = cursor.fetchall()
                
                # è½¬æ¢ä¸ºKnowledgeNodeå¯¹è±¡å¹¶è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
                results = []
                for row in rows:
                    node = KnowledgeNode(
                        id=row[0],
                        content=row[1],
                        node_type=row[2],
                        domain=row[3],
                        importance=row[4],
                        created_at=row[5],
                        metadata=json.loads(row[6])
                    )
                    
                    # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                    score = self._calculate_relevance_score(node, query_terms)
                    results.append((node, score))
                
                # æŒ‰åˆ†æ•°æ’åº
                results.sort(key=lambda x: x[1], reverse=True)
                return results
                
        except Exception as e:
            print(f"âŒ èŠ‚ç‚¹æœç´¢å¤±è´¥: {e}")
            return []
    
    def _find_connected_nodes(self, nodes: List[Tuple[KnowledgeNode, float]], limit: int) -> List[Tuple[KnowledgeNode, float]]:
        """æŸ¥æ‰¾ç›¸å…³è”çš„èŠ‚ç‚¹"""
        if not nodes:
            return []
        
        try:
            node_ids = [node.id for node, _ in nodes[:3]]  # åªä½¿ç”¨å‰3ä¸ªæœ€ç›¸å…³çš„èŠ‚ç‚¹
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æŸ¥æ‰¾ç›¸å…³è”çš„èŠ‚ç‚¹
                placeholders = ",".join(["?"] * len(node_ids))
                query_sql = f"""
                    SELECT DISTINCT n.id, n.content, n.node_type, n.domain, 
                           n.importance, n.created_at, n.metadata, e.weight
                    FROM knowledge_nodes n
                    JOIN knowledge_edges e ON (n.id = e.target_id OR n.id = e.source_id)
                    WHERE (e.source_id IN ({placeholders}) OR e.target_id IN ({placeholders}))
                    AND n.id NOT IN ({placeholders})
                    ORDER BY e.weight DESC, n.importance DESC
                    LIMIT ?
                """
                
                params = node_ids + node_ids + node_ids + [limit]
                cursor.execute(query_sql, params)
                rows = cursor.fetchall()
                
                # è½¬æ¢ç»“æœ
                connected_results = []
                for row in rows:
                    node = KnowledgeNode(
                        id=row[0],
                        content=row[1],
                        node_type=row[2],
                        domain=row[3],
                        importance=row[4],
                        created_at=row[5],
                        metadata=json.loads(row[6])
                    )
                    
                    # è¿æ¥èŠ‚ç‚¹çš„åˆ†æ•°åŸºäºè¾¹æƒé‡å’Œé‡è¦æ€§
                    edge_weight = row[7]
                    score = (edge_weight * 0.6 + node.importance * 0.4)
                    connected_results.append((node, score))
                
                return connected_results
                
        except Exception as e:
            print(f"âŒ è¿æ¥èŠ‚ç‚¹æŸ¥æ‰¾å¤±è´¥: {e}")
            return []
    
    def _calculate_relevance_score(self, node: KnowledgeNode, query_terms: List[str]) -> float:
        """è®¡ç®—èŠ‚ç‚¹ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ•°"""
        content_lower = node.content.lower()
        
        # æ–‡æœ¬åŒ¹é…åˆ†æ•°
        match_score = 0.0
        for term in query_terms:
            if term.lower() in content_lower:
                match_score += 1.0
        
        # æ ‡å‡†åŒ–åŒ¹é…åˆ†æ•°
        match_score = match_score / len(query_terms) if query_terms else 0.0
        
        # ç»¼åˆåˆ†æ•°ï¼šåŒ¹é…åº¦ + é‡è¦æ€§
        final_score = match_score * 0.7 + node.importance * 0.3
        
        return min(final_score, 1.0)
    
    def _rank_and_filter_results(
        self, 
        results: List[Tuple[KnowledgeNode, float]], 
        original_query: str, 
        limit: int
    ) -> List[Tuple[KnowledgeNode, float]]:
        """æ’åºå’Œè¿‡æ»¤æœ€ç»ˆç»“æœ"""
        # å»é‡ï¼ˆåŸºäºèŠ‚ç‚¹IDï¼‰
        seen_ids = set()
        unique_results = []
        
        for node, score in results:
            if node.id not in seen_ids:
                seen_ids.add(node.id)
                unique_results.append((node, score))
        
        # æŒ‰åˆ†æ•°æ’åº
        unique_results.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›å‰Nä¸ªç»“æœ
        return unique_results[:limit]
    
    def add_knowledge_node(self, node: KnowledgeNode) -> bool:
        """æ·»åŠ æ–°çš„çŸ¥è¯†èŠ‚ç‚¹"""
        try:
            self._batch_insert_nodes([node])
            print(f"âœ… å·²æ·»åŠ çŸ¥è¯†èŠ‚ç‚¹: {node.id}")
            return True
        except Exception as e:
            print(f"âŒ æ·»åŠ çŸ¥è¯†èŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def add_knowledge_edge(self, edge: KnowledgeEdge) -> bool:
        """æ·»åŠ æ–°çš„çŸ¥è¯†è¾¹"""
        try:
            self._batch_insert_edges([edge])
            print(f"âœ… å·²æ·»åŠ çŸ¥è¯†è¾¹: {edge.source_id} -> {edge.target_id}")
            return True
        except Exception as e:
            print(f"âŒ æ·»åŠ çŸ¥è¯†è¾¹å¤±è´¥: {e}")
            return False
    
    async def add_document_knowledge(
        self, 
        character_id: str, 
        file_content: bytes, 
        filename: str, 
        user_id: str
    ) -> Tuple[bool, str]:
        """
        æ·»åŠ æ–‡æ¡£çŸ¥è¯†åˆ°è§’è‰²çŸ¥è¯†åº“
        
        Args:
            character_id: è§’è‰²ID
            file_content: æ–‡ä»¶å†…å®¹
            filename: æ–‡ä»¶å
            user_id: ç”¨æˆ·ID
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ¶ˆæ¯)
        """
        try:
            print(f"ğŸ“š ä¸ºè§’è‰² {character_id} æ·»åŠ æ–‡æ¡£çŸ¥è¯†: {filename}")
            
            success, message, metadata = await document_processor.upload_file(
                file_content, filename, character_id, user_id
            )
            
            if success:
                print(f"âœ… æ–‡æ¡£çŸ¥è¯†æ·»åŠ æˆåŠŸ: {filename}")
                return True, f"æ–‡æ¡£ {filename} ä¸Šä¼ æˆåŠŸï¼Œå·²æ·»åŠ åˆ° {character_id} çš„çŸ¥è¯†åº“"
            else:
                print(f"âŒ æ–‡æ¡£çŸ¥è¯†æ·»åŠ å¤±è´¥: {message}")
                return False, message
                
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡æ¡£çŸ¥è¯†å¤±è´¥: {e}")
            return False, f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}"
    
    def get_character_documents(self, character_id: str) -> List[Dict[str, Any]]:
        """
        è·å–è§’è‰²çš„æ‰€æœ‰æ–‡æ¡£
        
        Args:
            character_id: è§’è‰²ID
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        try:
            files = document_processor.get_character_files(character_id)
            
            return [
                {
                    "file_id": file.file_id,
                    "filename": file.filename,
                    "file_type": file.file_type,
                    "file_size": file.file_size,
                    "upload_time": file.upload_time,
                    "page_count": file.page_count,
                    "word_count": file.word_count,
                    "summary": file.summary,
                    "keywords": file.keywords
                }
                for file in files
            ]
            
        except Exception as e:
            print(f"âŒ è·å–è§’è‰²æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    def delete_character_document(self, character_id: str, file_id: str) -> bool:
        """
        åˆ é™¤è§’è‰²æ–‡æ¡£
        
        Args:
            character_id: è§’è‰²ID
            file_id: æ–‡ä»¶ID
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            return document_processor.delete_character_file(character_id, file_id)
        except Exception as e:
            print(f"âŒ åˆ é™¤è§’è‰²æ–‡æ¡£å¤±è´¥: {e}")
            return False


# åˆ›å»ºå…¨å±€Graph RAGå®ä¾‹
graph_rag = GraphRAGSystem()
