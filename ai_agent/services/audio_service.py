"""
éŸ³é¢‘æœåŠ¡æ¨¡å— - ç»Ÿä¸€ç®¡ç†ASRå’ŒTTSåŠŸèƒ½
æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼Œæä¾›æµå¼å’Œæ‰¹é‡å¤„ç†æ¥å£
"""

import os
import base64
import io
import tempfile
from typing import Optional, Dict, Any, Union, AsyncGenerator
import numpy as np
import soundfile as sf
from pydub import AudioSegment
import dashscope
from dashscope.audio.tts import SpeechSynthesizer
import asyncio

from ..config import Config


class AudioService:
    """éŸ³é¢‘å¤„ç†æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–éŸ³é¢‘æœåŠ¡"""
        self.api_key = Config.DASHSCOPE_API_KEY
        self.sample_rate = Config.SAMPLE_RATE
        self.channels = Config.CHANNELS
        
        # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
        self.supported_formats = ['wav', 'mp3', 'm4a', 'flac', 'ogg']
        
        print(f"âœ… éŸ³é¢‘æœåŠ¡åˆå§‹åŒ–å®Œæˆ - é‡‡æ ·ç‡: {self.sample_rate}, å£°é“: {self.channels}")
    
    def convert_audio_format(
        self, 
        audio_data: bytes, 
        source_format: str, 
        target_format: str = 'wav'
    ) -> bytes:
        """
        è½¬æ¢éŸ³é¢‘æ ¼å¼
        
        Args:
            audio_data: åŸå§‹éŸ³é¢‘æ•°æ®
            source_format: æºæ ¼å¼
            target_format: ç›®æ ‡æ ¼å¼
            
        Returns:
            è½¬æ¢åçš„éŸ³é¢‘æ•°æ®
        """
        try:
            # ä½¿ç”¨pydubè¿›è¡Œæ ¼å¼è½¬æ¢
            audio = AudioSegment.from_file(
                io.BytesIO(audio_data), 
                format=source_format
            )
            
            # ç»Ÿä¸€é‡‡æ ·ç‡å’Œå£°é“
            audio = audio.set_frame_rate(self.sample_rate)
            audio = audio.set_channels(self.channels)
            
            # å¯¼å‡ºä¸ºç›®æ ‡æ ¼å¼
            output_buffer = io.BytesIO()
            audio.export(output_buffer, format=target_format)
            
            return output_buffer.getvalue()
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            raise
    
    def prepare_audio_for_asr(self, audio_data: bytes, source_format: str = 'wav') -> str:
        """
        ä¸ºASRå‡†å¤‡éŸ³é¢‘æ•°æ®
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            source_format: æºæ ¼å¼
            
        Returns:
            base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
        """
        try:
            # è½¬æ¢ä¸ºwavæ ¼å¼
            if source_format != 'wav':
                audio_data = self.convert_audio_format(audio_data, source_format, 'wav')
            
            # base64ç¼–ç 
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            return audio_base64
            
        except Exception as e:
            print(f"âŒ ASRéŸ³é¢‘å‡†å¤‡å¤±è´¥: {e}")
            raise
    
    async def speech_to_text(
        self, 
        audio_data: Union[bytes, str], 
        source_format: str = 'wav',
        language: str = 'zh'
    ) -> Dict[str, Any]:
        """
        è¯­éŸ³è½¬æ–‡å­— (ASR)
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰æˆ–base64å­—ç¬¦ä¸²
            source_format: éŸ³é¢‘æ ¼å¼
            language: è¯­è¨€ä»£ç 
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        try:
            # å¤„ç†éŸ³é¢‘æ•°æ®
            if isinstance(audio_data, bytes):
                audio_base64 = self.prepare_audio_for_asr(audio_data, source_format)
            else:
                audio_base64 = audio_data
            
            # æ„å»ºASRè¯·æ±‚
            messages = [
                {
                    "role": "system",
                    "content": [{"text": ""}]
                },
                {
                    "role": "user",
                    "content": [
                        {"audio": f"data:audio/wav;base64,{audio_base64}"},
                    ]
                }
            ]
            
            # è°ƒç”¨DashScope ASR API
            response = dashscope.MultiModalConversation.call(
                api_key=self.api_key,
                model=Config.ASR_MODEL,
                messages=messages,
                result_format="message",
                asr_options={
                    "enable_lid": True,  # è¯­è¨€è¯†åˆ«
                    "enable_itn": True   # æ•°å­—è½¬æ¢
                }
            )
            
            if response.status_code == 200:
                # æå–è¯†åˆ«ç»“æœ
                result_text = ""
                if hasattr(response, 'output') and hasattr(response.output, 'choices'):
                    if len(response.output.choices) > 0:
                        choice = response.output.choices[0]
                        if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                            result_text = choice.message.content
                
                return {
                    "success": True,
                    "text": result_text,
                    "language": language,
                    "confidence": 1.0,  # DashScopeä¸æä¾›ç½®ä¿¡åº¦
                    "duration": 0  # æš‚æ— æŒç»­æ—¶é—´ä¿¡æ¯
                }
            else:
                return {
                    "success": False,
                    "error": f"ASR APIè°ƒç”¨å¤±è´¥: {response.message}",
                    "text": ""
                }
                
        except Exception as e:
            print(f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "text": ""
            }
    
    async def text_to_speech(
        self, 
        text: str, 
        voice: str = "Cherry",
        speed: float = 1.0,
        stream: bool = False
    ) -> Union[bytes, AsyncGenerator[bytes, None]]:
        """
        æ–‡å­—è½¬è¯­éŸ³ (TTS)
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: å£°éŸ³ç±»å‹
            speed: è¯­é€Ÿå€ç‡
            stream: æ˜¯å¦æµå¼è¿”å›
            
        Returns:
            éŸ³é¢‘æ•°æ®æˆ–éŸ³é¢‘æµ
        """
        try:
            if stream:
                return self._text_to_speech_stream(text, voice, speed)
            else:
                return await self._text_to_speech_batch(text, voice, speed)
                
        except Exception as e:
            print(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            raise
    
    async def _text_to_speech_batch(
        self, 
        text: str, 
        voice: str, 
        speed: float
    ) -> bytes:
        """æ‰¹é‡TTSå¤„ç†"""
        try:
            response = dashscope.MultiModalConversation.call(
                api_key=self.api_key,
                model=Config.TTS_MODEL,
                text=text,
                voice=voice,
                language_type="Chinese",
                stream=False
            )
            
            if hasattr(response, 'output') and hasattr(response.output, 'audio'):
                audio_data = response.output.audio.data
                return base64.b64decode(audio_data)
            else:
                raise Exception("TTSå“åº”ä¸­æ²¡æœ‰éŸ³é¢‘æ•°æ®")
                
        except Exception as e:
            print(f"âŒ æ‰¹é‡TTSå¤„ç†å¤±è´¥: {e}")
            raise
    
    async def _text_to_speech_stream(
        self, 
        text: str, 
        voice: str, 
        speed: float
    ) -> AsyncGenerator[bytes, None]:
        """æµå¼TTSå¤„ç†"""
        try:
            response = dashscope.MultiModalConversation.call(
                api_key=self.api_key,
                model=Config.TTS_MODEL,
                text=text,
                voice=voice,
                language_type="Chinese",
                stream=True
            )
            
            for chunk in response:
                if (hasattr(chunk, 'output') and 
                    hasattr(chunk.output, 'audio') and 
                    chunk.output.audio is not None):
                    
                    audio_data = base64.b64decode(chunk.output.audio.data)
                    yield audio_data
                    
                if (hasattr(chunk, 'output') and 
                    hasattr(chunk.output, 'finish_reason') and 
                    chunk.output.finish_reason == "stop"):
                    break
                    
        except Exception as e:
            print(f"âŒ æµå¼TTSå¤„ç†å¤±è´¥: {e}")
            raise
    
    def save_audio_to_file(
        self, 
        audio_data: bytes, 
        file_path: str, 
        audio_format: str = 'wav'
    ):
        """
        ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            file_path: æ–‡ä»¶è·¯å¾„
            audio_format: éŸ³é¢‘æ ¼å¼
        """
        try:
            with open(file_path, 'wb') as f:
                f.write(audio_data)
            
            print(f"âœ… éŸ³é¢‘å·²ä¿å­˜åˆ°: {file_path}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def load_audio_from_file(self, file_path: str) -> bytes:
        """
        ä»æ–‡ä»¶åŠ è½½éŸ³é¢‘
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ•°æ®
        """
        try:
            with open(file_path, 'rb') as f:
                return f.read()
                
        except Exception as e:
            print(f"âŒ åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def get_audio_info(self, audio_data: bytes, audio_format: str = 'wav') -> Dict[str, Any]:
        """
        è·å–éŸ³é¢‘ä¿¡æ¯
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            audio_format: éŸ³é¢‘æ ¼å¼
            
        Returns:
            éŸ³é¢‘ä¿¡æ¯
        """
        try:
            audio = AudioSegment.from_file(
                io.BytesIO(audio_data), 
                format=audio_format
            )
            
            return {
                "duration": len(audio) / 1000.0,  # ç§’
                "frame_rate": audio.frame_rate,
                "channels": audio.channels,
                "sample_width": audio.sample_width,
                "frame_count": audio.frame_count(),
                "format": audio_format
            }
            
        except Exception as e:
            print(f"âŒ è·å–éŸ³é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    async def test_audio_pipeline(self, test_text: str = "ä½ å¥½ï¼Œæˆ‘æ˜¯FamilyBotæµ‹è¯•è¯­éŸ³ã€‚") -> bool:
        """
        æµ‹è¯•éŸ³é¢‘å¤„ç†ç®¡é“
        
        Args:
            test_text: æµ‹è¯•æ–‡æœ¬
            
        Returns:
            æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"ğŸ§ª å¼€å§‹æµ‹è¯•éŸ³é¢‘ç®¡é“...")
            
            # æµ‹è¯•TTS
            print(f"ğŸ“¢ æµ‹è¯•TTS: {test_text}")
            audio_data = await self.text_to_speech(test_text)
            
            if not audio_data:
                print("âŒ TTSæµ‹è¯•å¤±è´¥")
                return False
            
            print(f"âœ… TTSæˆåŠŸï¼Œç”Ÿæˆ {len(audio_data)} å­—èŠ‚éŸ³é¢‘æ•°æ®")
            
            # è·å–éŸ³é¢‘ä¿¡æ¯
            audio_info = self.get_audio_info(audio_data)
            print(f"ğŸµ éŸ³é¢‘ä¿¡æ¯: {audio_info}")
            
            # æµ‹è¯•ASRï¼ˆä½¿ç”¨ç”Ÿæˆçš„éŸ³é¢‘ï¼‰
            print(f"ğŸ™ï¸ æµ‹è¯•ASR...")
            asr_result = await self.speech_to_text(audio_data)
            
            if asr_result["success"]:
                print(f"âœ… ASRæˆåŠŸ: {asr_result['text']}")
                return True
            else:
                print(f"âŒ ASRå¤±è´¥: {asr_result['error']}")
                return False
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
            return False


# å…¨å±€éŸ³é¢‘æœåŠ¡å®ä¾‹
audio_service = AudioService()
